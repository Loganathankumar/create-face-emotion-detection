{"@context":{"@language":"en","@vocab":"https://schema.org/","citeAs":"cr:citeAs","column":"cr:column","conformsTo":"dct:conformsTo","cr":"http://mlcommons.org/croissant/","data":{"@id":"cr:data","@type":"@json"},"dataBiases":"cr:dataBiases","dataCollection":"cr:dataCollection","dataType":{"@id":"cr:dataType","@type":"@vocab"},"dct":"http://purl.org/dc/terms/","extract":"cr:extract","field":"cr:field","fileProperty":"cr:fileProperty","fileObject":"cr:fileObject","fileSet":"cr:fileSet","format":"cr:format","includes":"cr:includes","isEnumeration":"cr:isEnumeration","jsonPath":"cr:jsonPath","key":"cr:key","md5":"cr:md5","parentField":"cr:parentField","path":"cr:path","personalSensitiveInformation":"cr:personalSensitiveInformation","recordSet":"cr:recordSet","references":"cr:references","regex":"cr:regex","repeated":"cr:repeated","replace":"cr:replace","sc":"https://schema.org/","separator":"cr:separator","source":"cr:source","subField":"cr:subField","transform":"cr:transform","wd":"https://www.wikidata.org/wiki/"},"alternateName":"Learn facial expressions from an image","conformsTo":"http://mlcommons.org/croissant/1.0","license":{"@type":"sc:CreativeWork","name":"Database: Open Database, Contents: Database Contents","url":"http://opendatacommons.org/licenses/dbcl/1.0/"},"distribution":[{"contentUrl":"https://www.kaggle.com/api/v1/datasets/download/msambare/fer2013?datasetVersionNumber=1","contentSize":"60.321 MB","md5":"n1h5R0b/SWvhLPC7Jnnj1A==","encodingFormat":"application/zip","@id":"archive.zip","@type":"cr:FileObject","name":"archive.zip","description":"Archive containing all the contents of the FER-2013 dataset"},{"includes":"*.jpg","containedIn":{"@id":"archive.zip"},"encodingFormat":"image/jpeg","@id":"image-jpeg_fileset","@type":"cr:FileSet","name":"image/jpeg files","description":"image/jpeg files contained in archive.zip"}],"version":1,"keywords":["subject \u003E arts and entertainment \u003E art","subject \u003E arts and entertainment"],"isAccessibleForFree":true,"includedInDataCatalog":{"@type":"sc:DataCatalog","name":"Kaggle","url":"https://www.kaggle.com"},"creator":{"@type":"sc:Person","name":"Manas Sambare","url":"/msambare","image":"https://storage.googleapis.com/kaggle-avatars/thumbnails/3187350-kg.jpg"},"publisher":{"@type":"sc:Organization","name":"Kaggle","url":"https://www.kaggle.com/organizations/kaggle","image":"https://storage.googleapis.com/kaggle-organizations/4/thumbnail.png"},"thumbnailUrl":"https://storage.googleapis.com/kaggle-datasets-images/786787/1351797/89e6e907cb903b4f523bbd613e46b8a8/dataset-card.png?t=2020-07-19-18-42-52","dateModified":"2020-07-19T12:24:26.627","datePublished":"2020-07-19T17:21:52.5408666","@type":"sc:Dataset","name":"FER-2013","url":"https://www.kaggle.com/datasets/msambare/fer2013/versions/1","description":"The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centred and occupies about the same amount of space in each image. \n\nThe task is to categorize each face based on the emotion shown in the facial expression into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). The training set consists of 28,709 examples and the public test set consists of 3,589 examples."}